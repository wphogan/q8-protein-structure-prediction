{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../preprocess/CB513.json', 'r') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-123a9cc6df61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "d[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "device=\"cuda:0\"\n",
    "class S2S(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features=22,\n",
    "                       size_embedding=21,\n",
    "                       bidirectional=False,\n",
    "                       encoder_hidden_size=250,\n",
    "                       decoder_hidden_size=250):\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        \n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_size=size_embedding, \n",
    "                               hidden_size=encoder_hidden_size, \n",
    "                               num_layers=1, \n",
    "                               batch_first=True, \n",
    "                               bidirectional=bidirectional)\n",
    "        \n",
    "        # Concatenate the prev sequence + embedding\n",
    "        self.decoder = nn.LSTM(input_size=size_embedding * 2,\n",
    "                               hidden_size=decoder_hidden_size,\n",
    "                               num_layers=1,\n",
    "                               batch_first=True,\n",
    "                               bidirectional=False)\n",
    "        \n",
    "        # Embed the one hot vector 22 into 21 -> 21 b/c easier to concatenate w/ the PSSM row this way\n",
    "        self.embedding = nn.Embedding(num_features, size_embedding)\n",
    "        \n",
    "        self.hidden_to_pssm = nn.Linear(decoder_hidden_size, 21)\n",
    "        \n",
    "\n",
    "    def forward(self, x, pssm):\n",
    "        # Convert to non one-hot for embedding\n",
    "        x = x.argmax(axis=1)\n",
    "        \n",
    "        # Embedding layer\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Don't need the singular hidden state\n",
    "        _, (h, c) = self.encoder(x)\n",
    "\n",
    "        # Teacher force pssm during training\n",
    "        x = torch.cat([x, pssm], axis=2)\n",
    "        \n",
    "        out, _ = self.decoder(x, (h, c))\n",
    "        out = self.hidden_to_pssm(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class S2SDataset(data.Dataset):\n",
    "    def __init__(self, protein_data, ids):\n",
    "\n",
    "        data_len = len(ids)\n",
    "\n",
    "        # data_len, 700, 22 one hot\n",
    "        all_encodings = np.zeros([data_len, 700, 22])\n",
    "        \n",
    "        # data_len, 700 x 21 PSSM\n",
    "        all_pssm = np.zeros([data_len, 700, 21])\n",
    "        all_lengths = []\n",
    "\n",
    "        for i, id in enumerate(ids):\n",
    "            id = str(id)\n",
    "            if i % 250 == 0:\n",
    "                print(\"Loading {0}/{1} proteins\".format(i, len(ids)))\n",
    "\n",
    "            d = protein_data[id]\n",
    "            protein_length = d[\"protein_length\"]\n",
    "            all_lengths.append(protein_length)\n",
    "            \n",
    "            reshaped = np.array(d[\"protein_encoding\"]).reshape([700, -1])\n",
    "\n",
    "            all_encodings[i, :] = reshaped[:, 0:22]\n",
    "            all_pssm[i, :] = reshaped[:, 29:50]\n",
    "\n",
    "        self.all_encodings = all_encodings.astype(np.uint8)\n",
    "        self.all_pssm = all_pssm.astype(np.float32)\n",
    "        self.all_lengths = np.array(all_lengths).astype(np.int32)\n",
    "\n",
    "        print(len(all_pssm), len(all_pssm), len(all_lengths))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Returns one data pair (image and caption).\"\"\"\n",
    "        encoding = self.all_encodings[index]\n",
    "        pssm = self.all_pssm[index]\n",
    "        length = self.all_lengths[index]\n",
    "\n",
    "        return encoding, pssm, length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_encodings)\n",
    "\n",
    "\n",
    "def get_loader(protein_data, ids, batch_size, shuffle, num_workers):\n",
    "    \"\"\"Returns torch.utils.data.DataLoader\"\"\"\n",
    "\n",
    "    protein = S2SDataset(protein_data, ids)\n",
    "\n",
    "    # def collate_fn(data):\n",
    "    #     return data\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(dataset=protein,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=shuffle,\n",
    "                                              num_workers=num_workers, )\n",
    "    # collate_fn=collate_fn)\n",
    "    return data_loader, len(protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 0/3 proteins\n",
      "3 3 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "len_train = len(d)\n",
    "\n",
    "ids = np.random.choice(len_train, len_train, replace=False)\n",
    "\n",
    "\n",
    "val_loader, len_val = get_loader(protein_data=d,\n",
    "                                 ids=[0, 1, 2],\n",
    "                                 batch_size=5,\n",
    "                                 num_workers=1,\n",
    "                                 shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2142, 0.1708, 0.0230,  ..., 0.2709, 0.2689, 0.9234],\n",
       "        [0.0832, 0.0105, 0.0423,  ..., 0.0042, 0.1192, 0.0092],\n",
       "        [0.3475, 0.0253, 0.9945,  ..., 0.0111, 0.5000, 0.0251],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 700, 21])\n",
      "torch.Size([3, 700, 22])\n"
     ]
    }
   ],
   "source": [
    "for iter, (X, Y, seq_lens) in enumerate(val_loader):\n",
    "    print(Y.shape)\n",
    "    print(X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 22, 700])\n"
     ]
    }
   ],
   "source": [
    "for iter, (X, Y, seq_lens) in enumerate(val_loader):\n",
    "    X = X.permute([0, 2, 1]).long().to(device)\n",
    "    Y = Y.to(device)\n",
    "    print(X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class S2S(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features=22,\n",
    "                       size_embedding=21,\n",
    "                       bidirectional=False,\n",
    "                       encoder_hidden_size=250,\n",
    "                       decoder_hidden_size=250):\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        \n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_size=size_embedding, \n",
    "                               hidden_size=encoder_hidden_size, \n",
    "                               num_layers=1, \n",
    "                               batch_first=True, \n",
    "                               bidirectional=bidirectional)\n",
    "        \n",
    "        # Concatenate the prev sequence + embedding\n",
    "        self.decoder = nn.LSTM(input_size=size_embedding * 2,\n",
    "                               hidden_size=decoder_hidden_size,\n",
    "                               num_layers=1,\n",
    "                               batch_first=True,\n",
    "                               bidirectional=False)\n",
    "        \n",
    "        # Embed the one hot vector 22 into 21 -> 21 b/c easier to concatenate w/ the PSSM row this way\n",
    "        self.embedding = nn.Embedding(num_features, size_embedding)\n",
    "        \n",
    "        self.hidden_to_pssm = nn.Linear(decoder_hidden_size, 21)\n",
    "        \n",
    "\n",
    "    def forward(self, x, pssm):\n",
    "        # Convert to non one-hot for embedding\n",
    "        x = x.argmax(axis=1)\n",
    "        \n",
    "        # Embedding layer\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # Don't need the singular hidden state\n",
    "        _, (h, c) = self.encoder(x)\n",
    "\n",
    "        # Teacher force pssm during training\n",
    "        x = torch.cat([x, pssm], axis=2)\n",
    "        \n",
    "        out, _ = self.decoder(x, (h, c))\n",
    "        out = self.hidden_to_pssm(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def gen(self, x):\n",
    "        # Convert to non one-hot for embedding\n",
    "        x = x.argmax(axis=1)\n",
    "\n",
    "        # Embedding layer\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Don't need the singular hidden state\n",
    "        _, (h, c) = self.encoder(x)\n",
    "\n",
    "        gen_seq = []\n",
    "        ht, ct = h, c\n",
    "        pred_seq = torch.ones_like(x[:, 0:1, :]).to(device)\n",
    "        \n",
    "        for t in range(x.shape[1]):\n",
    "            xt = x[:, t:t+1, :]\n",
    "            xt = torch.cat([xt, pred_seq], axis=2)\n",
    "\n",
    "            out, (ht, ct) = s2s.decoder(xt, (ht, ct))\n",
    "            pred_seq = s2s.hidden_to_pssm(out)\n",
    "            \n",
    "            gen_seq.append(pred_seq)\n",
    "\n",
    "        gen_seq = torch.cat(gen_seq, dim=1)\n",
    "\n",
    "        return gen_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s = S2S().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = s2s(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = s2s.gen(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 700, 21])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X.argmax(axis=1)\n",
    "x = s2s.embedding(x)\n",
    "_, (h, c) = s2s.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seq = torch.zeros_like(x[:, 0:1, :]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X.argmax(axis=1)\n",
    "\n",
    "# Embedding layer\n",
    "x = s2s.embedding(x)\n",
    "\n",
    "# Don't need the singular hidden state\n",
    "_, (h, c) = s2s.encoder(x)\n",
    "\n",
    "# Teacher force pssm during training\n",
    "x = torch.cat([x, Y], axis=2)\n",
    "\n",
    "out, _ = s2s.decoder(x, (h, c))\n",
    "out = s2s.hidden_to_pssm(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_seq = s2s.hidden_to_pssm(h).permute([1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 21])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_holder = torch.zeros_like(Y).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_holder[:, 0:1, :] = first_seq\n",
    "seq_holder[:, 1:, :] = Y[:, :Y.shape[1]-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 700, 21])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_holder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 700, 21])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_holder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 21])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 42, got 63",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d931f1710137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_seq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpred_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_to_pssm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# type: (Tensor, Tuple[Tensor, Tensor], Optional[Tensor]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n\u001b[1;32m    148\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 149\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 42, got 63"
     ]
    }
   ],
   "source": [
    "all_out = []\n",
    "ht, ct = h, c\n",
    "\n",
    "for t in range(x.shape[1]):\n",
    "    xt = x[:, t:t+1, :]\n",
    "    xt = torch.cat([xt, pred_seq], axis=2)\n",
    "\n",
    "    out, (ht, ct) = s2s.decoder(xt, (ht, ct))\n",
    "    pred_seq = s2s.hidden_to_pssm(out)\n",
    "    \n",
    "    all_out.append(pred_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_out = torch.cat(all_out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:, 0:1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(self, x):\n",
    "    # Convert to non one-hot for embedding\n",
    "    x = x.argmax(axis=1)\n",
    "\n",
    "    # Embedding layer\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # Don't need the singular hidden state\n",
    "    _, (h, c) = self.encoder(x)\n",
    "\n",
    "    gen_seq = []\n",
    "    ht, ct = h, c\n",
    "\n",
    "    for t in range(x.shape[1]):\n",
    "        xt = x[:, t:t+1, :]\n",
    "        xt = torch.cat([xt, pred_seq], axis=2)\n",
    "\n",
    "        out, (ht, ct) = s2s.decoder(xt, (ht, ct))\n",
    "        pred_seq = s2s.hidden_to_pssm(out)\n",
    "\n",
    "        gen.append(pred_seq)\n",
    "        \n",
    "    gen_seq = torch.cat(gen_seq, dim=1)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, model, stats_path,\n",
    "          train_loader, val_loader,\n",
    "          optimizer, criterion,\n",
    "          len_train, len_val,\n",
    "          latest_model_path,\n",
    "          best_model_path, optim_path, device, early_stop=10):\n",
    "    \n",
    "    fmt_string = \"Epoch[{0}/{1}], Batch[{2}/{3}], Train Loss: {4}\"\n",
    "\n",
    "    # Load stats if path exists\n",
    "    if os.path.exists(stats_path):\n",
    "        with open(stats_path, \"rb\") as f:\n",
    "            stats_dict = pkl.load(f)\n",
    "        print(stats_dict[\"best_epoch\"])\n",
    "        start_epoch = stats_dict[\"next_epoch\"]\n",
    "        min_val_loss = stats_dict[\"valid\"][stats_dict[\"best_epoch\"]][\"loss\"]\n",
    "        print(\"Stats exist. Loading from {0}. Starting from Epoch {1}\".format(stats_path, start_epoch))\n",
    "    else:\n",
    "        min_val_loss = np.inf\n",
    "        stats_dict = rec_dd()\n",
    "        start_epoch = 0\n",
    "\n",
    "        # See loss before training\n",
    "        val_loss = val(-1, model, val_loader, len_val, criterion, epochs, device, num_features, one_hot_embed)\n",
    "\n",
    "        # Update statistics dict\n",
    "        stats_dict[\"valid\"][-1][\"acc\"] = accs\n",
    "        stats_dict[\"valid\"][-1][\"loss\"] = val_loss\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        train_loss = 0.\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "\n",
    "        ts = time.time()\n",
    "        for iter, (X, Y, seq_lens) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            X = X.permute([0, 2, 1]).long().to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            outputs = model(X, Y)\n",
    "            \n",
    "            loss = 0\n",
    "            for y, t, seq_len in zip(outputs, Y, seq_lens):\n",
    "                y_cut = y[:seq_len]\n",
    "                t_cut = t[:seq_len]\n",
    "              \n",
    "                loss += criterion(y_cut, t_cut)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            if iter % 10 == 0:\n",
    "                print(fmt_string.format(epoch, epochs, iter, len(train_loader), loss.item()))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"\\nFinished Epoch {}, Time elapsed: {}, Loss: {}\".format(epoch, time.time() - ts,\n",
    "                                                                       train_loss / len(train_loader)))\n",
    "\n",
    "        # Avg train loss. Batch losses were un-averaged before when added to train_loss\n",
    "        stats_dict[\"train\"][epoch][\"loss\"] = train_loss / len(train_loader)\n",
    "\n",
    "        # The validation stats after additional epoch\n",
    "        accs, val_loss = val(epoch, model, val_loader, len_val, criterion, epochs, device)\n",
    "\n",
    "        # Update statistics dict\n",
    "        stats_dict[\"valid\"][epoch][\"loss\"] = val_loss\n",
    "        stats_dict[\"next_epoch\"] = epoch + 1\n",
    "\n",
    "        # Save latest model\n",
    "        torch.save(model, latest_model_path)\n",
    "\n",
    "        # Save optimizer state dict\n",
    "        optim_state = {'optimizer': optimizer.state_dict()}\n",
    "        torch.save(optim_state, optim_path)\n",
    "\n",
    "        if val_loss <= min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            # Save best model\n",
    "            torch.save(model, best_model_path)\n",
    "            stats_dict[\"best_epoch\"] = epoch\n",
    "        else:\n",
    "            early_stop -= 1\n",
    "\n",
    "        # Save stats\n",
    "        with open(stats_path, \"wb\") as f:\n",
    "            pkl.dump(stats_dict, f)\n",
    "\n",
    "        if early_stop == 0:\n",
    "            print('=' * 10, 'Early stopping.', '=' * 10)\n",
    "            break\n",
    "\n",
    "        # Set back to train mode\n",
    "        model.train()\n",
    "\n",
    "    return stats_dict, model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
